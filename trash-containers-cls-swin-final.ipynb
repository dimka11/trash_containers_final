{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install git+https://github.com/rwightman/pytorch-image-models\n!pip install -q -U albumentations","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:11:16.796827Z","iopub.execute_input":"2022-07-03T20:11:16.797669Z","iopub.status.idle":"2022-07-03T20:11:43.596132Z","shell.execute_reply.started":"2022-07-03T20:11:16.797568Z","shell.execute_reply":"2022-07-03T20:11:43.595033Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport glob\n\nimport IPython\nfrom IPython.display import FileLink\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom tqdm.auto import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import Flatten\nfrom torch.optim.lr_scheduler import StepLR\n\nfrom torch.utils.data import DataLoader, Dataset, Subset\n\nfrom torchvision import datasets, transforms\nfrom torchvision import models\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\n\nimport PIL\n\nimport timm\nfrom pprint import pprint\n\nfrom sklearn.preprocessing import label_binarize\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.manifold import TSNE\nimport umap\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-03T20:11:43.598611Z","iopub.execute_input":"2022-07-03T20:11:43.599015Z","iopub.status.idle":"2022-07-03T20:12:04.414050Z","shell.execute_reply.started":"2022-07-03T20:11:43.598974Z","shell.execute_reply":"2022-07-03T20:12:04.413011Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_csv = pd.read_csv('../input/trash-containers/train_dataset_train/train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:12:16.005572Z","iopub.execute_input":"2022-07-03T20:12:16.006716Z","iopub.status.idle":"2022-07-03T20:12:16.029186Z","shell.execute_reply.started":"2022-07-03T20:12:16.006677Z","shell.execute_reply":"2022-07-03T20:12:16.028282Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"sns.countplot(x = \"class\" , data  = train_csv)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:12:16.915330Z","iopub.execute_input":"2022-07-03T20:12:16.915756Z","iopub.status.idle":"2022-07-03T20:12:17.178004Z","shell.execute_reply.started":"2022-07-03T20:12:16.915716Z","shell.execute_reply":"2022-07-03T20:12:17.176843Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(2, 6, figsize=(22,8))\nfig.suptitle(f'Нет мусорок {\" \"*105} Есть мусорки {\" \"*105} другое', fontsize=14)\n\ntrain_path = '../input/trash-containers/train_dataset_train/train'\n\nfor i, name in zip(range(4), train_csv[ train_csv['class'] == 0 ].sample(4, random_state=42)['ID_img']):\n    axs[i // 2, (i % 2)].imshow(plt.imread(f\"{train_path}/{name}\"))\n    axs[i // 2, (i % 2)].axis('off')\n\nfor i, name in zip(range(4), train_csv[ train_csv['class'] == 1 ].sample(4, random_state=42)['ID_img']):\n    axs[i // 2, (i % 2)+2].imshow(plt.imread(f\"{train_path}/{name}\"))\n    axs[i // 2, (i % 2)+2].axis('off')\n    \nfor i, name in zip(range(4), train_csv[ train_csv['class'] == 2 ].sample(4, random_state=42)['ID_img']):\n    axs[i // 2, (i % 2)+4].imshow(plt.imread(f\"{train_path}/{name}\"))\n    axs[i // 2, (i % 2)+4].axis('off')\n\nfig.tight_layout()\nfig.subplots_adjust(top=0.88)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:12:19.001072Z","iopub.execute_input":"2022-07-03T20:12:19.001640Z","iopub.status.idle":"2022-07-03T20:12:21.745279Z","shell.execute_reply.started":"2022-07-03T20:12:19.001605Z","shell.execute_reply":"2022-07-03T20:12:21.744312Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### Data transform config","metadata":{}},{"cell_type":"code","source":"class ConfigDataTransform:\n    train_csv = pd.read_csv('../input/trash-containers/train_dataset_train/train.csv')\n    remove_dirty_labels = False\n    replace_dirty_labels = True","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:12:28.274340Z","iopub.execute_input":"2022-07-03T20:12:28.274765Z","iopub.status.idle":"2022-07-03T20:12:28.287524Z","shell.execute_reply.started":"2022-07-03T20:12:28.274728Z","shell.execute_reply":"2022-07-03T20:12:28.286554Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Remove dirty examples from train","metadata":{}},{"cell_type":"code","source":"if ConfigDataTransform.remove_dirty_labels or ConfigDataTransform.replace_dirty_labels:\n    r_from_0 = ['220304014444_93d324658e78782c37f3bce0c65e03b2.jpg', '220307012903_c2e25c71975244587fb02517aec28abb.jpg',\\\n                '220307023015_d7805fde0aeda728f0136ec7482cc43f.jpg', '220307023034_9d7ebe271649a6ebbc3494c026126869.jpg',\\\n                '220307024716_902e232dfe9c5ac55643703abcbf1d11.jpg', '220307123436_a755745087e8d1f6efb7dde875b3f1be.jpg']\n    r_from_1 = ['220301070625_1be30d27fcfc119ed8dee6037a9ab385.jpg','220301124526_ba6ffcfd54b8a2e2d7120082abf89be8.jpg',\\\n               '220302013218_0dc7f7864ff931e2f0e2673f89cfb47c.jpg','220303054740_9daab175576b21466a151bc4b9a0536f.jpg',\\\n               '220304060156_51b2fe94598d626677f65085635568fa.jpg','220304063326_d00d7a35c1490bf3ce4daeb58f8eaf7e.jpg',]\n    \n    train_csv = ConfigDataTransform.train_csv\n    r_from_0_idxs = train_csv[train_csv['ID_img'].isin(r_from_0)].index\n    r_from_1_idxs = train_csv[train_csv['ID_img'].isin(r_from_1)].index\n    \n    if ConfigDataTransform.remove_dirty_labels:\n        train_csv = train_csv.drop(r_from_0_idxs)\n        train_csv = train_csv.drop(r_from_1_idxs)\n        \n    if ConfigDataTransform.replace_dirty_labels:\n        train_csv.loc[r_from_0_idxs, 'class'] = 2\n        train_csv.loc[r_from_1_idxs, 'class'] = 2\n        \n    train_csv.to_csv('./train.csv', index=False);","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:12:34.240263Z","iopub.execute_input":"2022-07-03T20:12:34.240611Z","iopub.status.idle":"2022-07-03T20:12:34.259377Z","shell.execute_reply.started":"2022-07-03T20:12:34.240583Z","shell.execute_reply":"2022-07-03T20:12:34.258443Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Config","metadata":{}},{"cell_type":"code","source":"class Config:\n    IMG_SIZE_H = 224\n    IMG_SIZE_W = 224\n    BATCH_SIZE = 128\n    EPOCHS = 25\n    FT_EPOCHS = 31\n    VAL_IN_EPOCHS = 1\n    DEVICE = torch.device('cuda')\n#     MODEL_LOAD_PATH = '/content/best_model.pt'\n    train_images = '../input/trash-containers/train_dataset_train/train'\n    test_images = '../input/trash-containers/test_dataset_test'\n    val_csv_path = './val.csv'\n    load_val_from_csv = False\n    train_csv_path = './train.csv'\n    train = False\n    fine_tune = False\n    val = True # val dataset is mandatory for training\n    inference = True\n    submit = True\n    load_weights = True\n    weights_path_var = 'old' # old for load from Config.weights_path new for load from Config.new_current_weights_path\n    weights_path = '../input/trash-containers-cls-weights/swin224_ml_0.91.pt'\n    new_current_weights_path = None\n    augmentator='torchvision' #torchvision or albs\n    remove_old_weights = True\n    train_val_split = True # need to set train_val_split or load_val_from_csv\n    val_size = 0.25\n\nclass ModelConfig:\n    model_name = 'swin_large_patch4_window7_224'\n    linear_layer_input_size = 1536\n#     base_lr = 3e-3\n#     ft_lr = 3e-5\n#     opt = 'adamw'\n#     loss = ''\n\nif ConfigDataTransform.remove_dirty_labels or ConfigDataTransform.replace_dirty_labels:\n    Config.train_csv_path = './train.csv'\nelse:\n    Config.train_csv_path = '../input/trash-containers/train_dataset_train/train.csv'","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:31:33.045783Z","iopub.execute_input":"2022-07-03T20:31:33.048863Z","iopub.status.idle":"2022-07-03T20:31:33.062182Z","shell.execute_reply.started":"2022-07-03T20:31:33.048789Z","shell.execute_reply":"2022-07-03T20:31:33.061154Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":"Class weights","metadata":{}},{"cell_type":"code","source":"class_weights = compute_class_weight('balanced', classes=[0,1,2], y=pd.read_csv(Config.train_csv_path)['class'])\n\n# class_sample_count = np.unique(train_csv['class'].astype(int), return_counts=True)[1]\n# weight = 1. / class_sample_count\n# samples_weight = weight[train_csv['class'].astype(int)]\n# samples_weight = torch.from_numpy(samples_weight)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:22:15.393192Z","iopub.execute_input":"2022-07-03T20:22:15.393554Z","iopub.status.idle":"2022-07-03T20:22:15.404338Z","shell.execute_reply.started":"2022-07-03T20:22:15.393526Z","shell.execute_reply":"2022-07-03T20:22:15.403298Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"# Augmentations","metadata":{}},{"cell_type":"code","source":"if Config.augmentator == 'torchvision':\n    transform_train = transforms.Compose([\n            #  transforms.CenterCrop(2048),\n            #  transforms.RandomResizedCrop(2048),\n             transforms.Resize((Config.IMG_SIZE_H, Config.IMG_SIZE_W)),\n             transforms.RandomHorizontalFlip(p=0.5),\n             transforms.RandomVerticalFlip(p=0.5),\n             transforms.RandomRotation(90),\n    #          transforms.RandomAffine(10, translate=(0, 0.1), scale=(1, 1), shear=5, interpolation=transforms.InterpolationMode.BILINEAR, fill=0),\n    #          transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0),\n    #          transforms.RandomRotation(180),\n    #          transforms.RandomRotation(270),\n    #          transforms.RandomVerticalFlip(),\n             transforms.ToTensor(),\n             transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                  std=[0.229, 0.224, 0.225]),\n    ])\n\n    transform_test = transforms.Compose([\n            #  transforms.CenterCrop(2048),\n             transforms.Resize((Config.IMG_SIZE_H, Config.IMG_SIZE_W)),\n             transforms.ToTensor(),\n             transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                  std=[0.229, 0.224, 0.225]),\n    ])","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:15:25.367835Z","iopub.execute_input":"2022-07-03T20:15:25.368205Z","iopub.status.idle":"2022-07-03T20:15:25.376953Z","shell.execute_reply.started":"2022-07-03T20:15:25.368173Z","shell.execute_reply":"2022-07-03T20:15:25.375777Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"if Config.augmentator == 'albs':\n    transform_train = A.Compose([\n            A.LongestMaxSize(max_size=Config.IMG_SIZE_H, interpolation=1),\n    #         A.PadIfNeeded(min_height=Config.IMG_SIZE_H, min_width=Config.IMG_SIZE_W, border_mode=0, value=(0,0,0)),\n            A.PadIfNeeded(Config.IMG_SIZE_H, Config.IMG_SIZE_W, p=1.0),\n    #         геометрические преобразования\n            A.HorizontalFlip(p=0.5),\n            A.VerticalFlip(p=0.5),\n            A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n            A.Rotate(limit=[0, 90], p=0.5),\n    #         цветовые преобразования\n            A.RandomBrightnessContrast(p=0.3),\n            # A.ToGray(p=0.1),\n            A.CLAHE(p=0.3),\n            A.FancyPCA(p=0.3),\n            # A.Blur(),\n            # A.GaussNoise(),\n            # A.InvertImg(),\n            # A.RGBShift(p=1),  \n            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n            ToTensorV2(),\n        ])\n\n    transform_test = transform_train = A.Compose([\n            A.LongestMaxSize(max_size=Config.IMG_SIZE_H, interpolation=1),\n            A.PadIfNeeded(Config.IMG_SIZE_H, Config.IMG_SIZE_W, p=1.0),\n            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n            ToTensorV2(),\n        ])","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:15:27.460032Z","iopub.execute_input":"2022-07-03T20:15:27.460387Z","iopub.status.idle":"2022-07-03T20:15:27.470346Z","shell.execute_reply.started":"2022-07-03T20:15:27.460358Z","shell.execute_reply":"2022-07-03T20:15:27.469332Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# DataSet","metadata":{}},{"cell_type":"code","source":"class CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, csv_path, images_folder, transform = None):\n        self.df = pd.read_csv(csv_path, index_col=0)\n        self.images_folder = images_folder\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        filename = self.df.iloc[index].name\n        label = int(self.df.iloc[index, 0])\n        image = PIL.Image.open(os.path.join(self.images_folder, filename))\n        \n        if self.transform is not None:\n            if Config.augmentator == \"torchvision\":\n                image = self.transform(image)\n                return image, label\n            if Config.augmentator == \"albs\":\n                image = self.transform(image=np.array(image))\n                return image['image'], label\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:15:32.598490Z","iopub.execute_input":"2022-07-03T20:15:32.598888Z","iopub.status.idle":"2022-07-03T20:15:32.608874Z","shell.execute_reply.started":"2022-07-03T20:15:32.598854Z","shell.execute_reply":"2022-07-03T20:15:32.606665Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"class CustomInferenceDataset(torch.utils.data.Dataset):\n    def __init__(self, images_folder, test_transform = None):\n        self.images_folder = images_folder\n        self.transform = test_transform\n        self.list_files = sorted(glob.glob(f'{images_folder}/*.jp*'))\n\n    def __len__(self):\n        return len(self.list_files)\n                                           \n    def __getitem__(self, index):\n        file_name = self.list_files[index]\n        image = PIL.Image.open(file_name)\n        if self.transform is not None:\n            if Config.augmentator == \"torchvision\":\n                image = self.transform(image)\n                return image, file_name.split('/')[-1]\n            if Config.augmentator == \"albs\":\n                image = self.transform(image=np.array(image))\n                return image['image'], file_name.split('/')[-1]\n        return image, file_name.split('/')[-1]","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:15:34.134210Z","iopub.execute_input":"2022-07-03T20:15:34.134557Z","iopub.status.idle":"2022-07-03T20:15:34.144823Z","shell.execute_reply.started":"2022-07-03T20:15:34.134530Z","shell.execute_reply":"2022-07-03T20:15:34.143963Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"train_ds = CustomDataset(Config.train_csv_path, Config.train_images, transform=transform_train)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:22:20.072489Z","iopub.execute_input":"2022-07-03T20:22:20.072895Z","iopub.status.idle":"2022-07-03T20:22:20.081583Z","shell.execute_reply.started":"2022-07-03T20:22:20.072863Z","shell.execute_reply":"2022-07-03T20:22:20.080604Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"Split to train/val","metadata":{}},{"cell_type":"code","source":"def subset_ind(dataset, ratio: float):\n    return np.random.choice(len(dataset), size=int(ratio*len(dataset)), replace=False)\n\nif Config.train_val_split:\n    val_size = Config.val_size\n    val_inds = subset_ind(train_ds, val_size)\n\n    train_dataset = Subset(train_ds, [i for i in range(len(train_ds)) if i not in val_inds])\n    val_dataset = Subset(train_ds, val_inds)\n    train_ds = train_dataset\n    val_ds = val_dataset\n\n    print(f'training size: {len(train_dataset)}\\nvalidation size: {len(val_dataset)}')","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:22:25.803663Z","iopub.execute_input":"2022-07-03T20:22:25.804133Z","iopub.status.idle":"2022-07-03T20:22:25.822928Z","shell.execute_reply.started":"2022-07-03T20:22:25.804093Z","shell.execute_reply":"2022-07-03T20:22:25.821764Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"if Config.load_val_from_csv:\n    val_ds = CustomDataset(Config.val_csv_path, Config.test_images, transform=transform_test)\n    \nif Config.inference:\n    test_ds = CustomInferenceDataset(Config.test_images, test_transform=transform_test)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:19:32.180054Z","iopub.execute_input":"2022-07-03T20:19:32.180410Z","iopub.status.idle":"2022-07-03T20:19:32.188050Z","shell.execute_reply.started":"2022-07-03T20:19:32.180382Z","shell.execute_reply":"2022-07-03T20:19:32.186841Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"visualize first 2 images from ds","metadata":{}},{"cell_type":"code","source":"def visualize_pic(ds, sample_count=2):\n    for i in range(0, sample_count):\n        image = torch.permute(ds[i][0], (1,2,0))\n        plt.imshow(image.numpy())\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:24:18.721136Z","iopub.execute_input":"2022-07-03T20:24:18.722066Z","iopub.status.idle":"2022-07-03T20:24:18.727588Z","shell.execute_reply.started":"2022-07-03T20:24:18.722029Z","shell.execute_reply":"2022-07-03T20:24:18.726375Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# train_ds[0]\nvisualize_pic(train_ds)\n# len(train_ds)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:24:20.594631Z","iopub.execute_input":"2022-07-03T20:24:20.595301Z","iopub.status.idle":"2022-07-03T20:24:21.007892Z","shell.execute_reply.started":"2022-07-03T20:24:20.595263Z","shell.execute_reply":"2022-07-03T20:24:21.006729Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"Dataloaders","metadata":{}},{"cell_type":"code","source":"train_loader = DataLoader(train_ds, batch_size=Config.BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=2)\nval_loader = DataLoader(val_ds, batch_size=Config.BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=2)\nif Config.inference:\n    test_loader = DataLoader(test_ds, batch_size=Config.BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:26:33.762016Z","iopub.execute_input":"2022-07-03T20:26:33.762405Z","iopub.status.idle":"2022-07-03T20:26:33.769229Z","shell.execute_reply.started":"2022-07-03T20:26:33.762374Z","shell.execute_reply":"2022-07-03T20:26:33.768205Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"model_names = timm.list_models(pretrained=True)\n# pprint(model_names)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:26:43.297728Z","iopub.execute_input":"2022-07-03T20:26:43.298400Z","iopub.status.idle":"2022-07-03T20:26:43.314512Z","shell.execute_reply.started":"2022-07-03T20:26:43.298367Z","shell.execute_reply":"2022-07-03T20:26:43.313293Z"},"scrolled":true,"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"models_names_s = ['swin_large_patch4_window12_384_in22k', 'swin_large_patch4_window7_224', 'swin_base_patch4_window12_384_in22k', 'vit_small_patch16_384', 'swinv2_base_window8_256']","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:26:52.842365Z","iopub.execute_input":"2022-07-03T20:26:52.842790Z","iopub.status.idle":"2022-07-03T20:26:52.847702Z","shell.execute_reply.started":"2022-07-03T20:26:52.842754Z","shell.execute_reply":"2022-07-03T20:26:52.846667Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"model = timm.create_model(models_names_s[1], in_chans = 3, pretrained = True, num_classes=0, global_pool='avg') # global_pool='catavgmax' # features_only=True\nprint(model.default_cfg)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:27:13.194614Z","iopub.execute_input":"2022-07-03T20:27:13.194969Z","iopub.status.idle":"2022-07-03T20:28:09.213569Z","shell.execute_reply.started":"2022-07-03T20:27:13.194941Z","shell.execute_reply":"2022-07-03T20:28:09.212589Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"dummy_image = torch.randn(1, 3, Config.IMG_SIZE_H, Config.IMG_SIZE_W)\nmodel.forward_features(dummy_image).shape\nmodel.forward(dummy_image).shape","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:28:09.215599Z","iopub.execute_input":"2022-07-03T20:28:09.217060Z","iopub.status.idle":"2022-07-03T20:28:11.113498Z","shell.execute_reply.started":"2022-07-03T20:28:09.217020Z","shell.execute_reply":"2022-07-03T20:28:11.112505Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"class SWIN(nn.Module):\n    def __init__(self, fc_layers=True, fc_layer_sz=256, base_model_output_size=1536):\n        super().__init__()\n        \n        self.fc_layers = fc_layers\n        self.fc_layer_sz = fc_layer_sz\n        self.base_model_output_size = base_model_output_size\n    \n        self.swin = timm.create_model(ModelConfig.model_name, in_chans = 3, pretrained = True, num_classes=0)\n        print(ModelConfig.model_name)\n        for param in self.swin.parameters():\n            param.requires_grad = False\n\n#         self.flatten = Flatten()\n        self.fc = nn.Linear(self.base_model_output_size, 3)\n        self.fc1 = nn.Linear(self.base_model_output_size, self.fc_layer_sz)\n        self.fc2 = nn.Linear(self.fc_layer_sz, 3)\n        \n        self.batchnorm = nn.BatchNorm1d(self.fc_layer_sz)\n        self.dropout = nn.Dropout(0.5)\n        self.relu = nn.ReLU()\n    \n    def fc_layer(self, x, after_first_layer=False):\n        if after_first_layer:\n            return self.fc1(x)\n        else:\n            x = self.relu(self.fc1(x))\n            x = self.batchnorm(x)\n            x = self.dropout(x)\n            return self.fc2(x)\n    \n    def forward(self, x):\n        x = self.swin(x)\n        \n        if self.fc_layers:\n            return self.fc_layer(x)\n        else:\n            x = self.fc(x)\n            return x\n    \n    def get_features(self, x, after_fc=False):\n        if after_fc and self.fc_layers:\n            x = self.swin(x)\n            return self.fc_layer(x, True)\n        if after_fc and not self.fc_layers:\n            return self.forward(x)\n        else:\n            return self.swin(x)\n        \n    def set_parameter_requires_grad(self, freeze: bool): # unused\n        for param in self.swin.parameters():\n            param.requires_grad = not freeze\n        if not freeze:\n            for name ,child in (self.swin.named_children()):\n                if name.find('norm') != -1: # norm BatchNorm\n                    for param in child.parameters():\n                        param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:28:38.475858Z","iopub.execute_input":"2022-07-03T20:28:38.476206Z","iopub.status.idle":"2022-07-03T20:28:38.490185Z","shell.execute_reply.started":"2022-07-03T20:28:38.476179Z","shell.execute_reply":"2022-07-03T20:28:38.489251Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"def save_model(epoch, net, optimizer, loss, metrics):\n    #                     torch.save(net.state_dict(), f'./best_model_{epoch}_{str(np.round(metrics, 3))}.pt')\n    torch.save({\n        'epoch': epoch, 'model_state_dict': net.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'loss': loss, }, f'./best_model_{epoch}_{str(np.round(metrics, 3))}.pt')\n    Config.new_current_weights_path = f'./best_model_{epoch}_{str(np.round(metrics, 3))}.pt'","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:28:42.476752Z","iopub.execute_input":"2022-07-03T20:28:42.477693Z","iopub.status.idle":"2022-07-03T20:28:42.484364Z","shell.execute_reply.started":"2022-07-03T20:28:42.477652Z","shell.execute_reply":"2022-07-03T20:28:42.483297Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"def train_batch_step(batch, device, optimizer, loss_fn, epoch_loss, train_size, train_pred):\n    X_batch, y_batch = batch\n\n    X_batch = X_batch.to(device)\n    y_batch = y_batch.to(device)\n\n    optimizer.zero_grad()\n    y_pred = net(X_batch)\n\n    loss1 = loss_fn[0](y_pred, F.one_hot(y_batch, num_classes=3).float())\n    loss2 = loss_fn[1](y_pred, F.one_hot(y_batch, num_classes=3).float())\n    loss = loss1 + loss2\n    \n    loss.backward()\n    optimizer.step()\n\n    y_pred = torch.sigmoid(y_pred)\n    y_pred = torch.argmax(y_pred, 1)\n\n    y_batch = y_batch.view(-1)\n    y_pred = y_pred.view(-1)\n\n    epoch_loss += y_pred.shape[0] * loss.item()\n\n    train_size += y_pred.size(0)\n    train_pred += torch.sum(y_pred == y_batch)\n    \n    return epoch_loss, train_size, train_pred, loss\n    \ndef val_batch_step(batch, device, net, loss_fn, epoch_val_loss, y_true_a, y_pred_a):\n    images, y_true = batch\n    images = images.to(device)\n    y_true = y_true.to(device)\n    y_pred = net(images)\n    loss1 = loss_fn[0](y_pred, F.one_hot(y_true, num_classes=3).float())\n    loss2 = loss_fn[1](y_pred, F.one_hot(y_true, num_classes=3).float())\n    loss = loss1 + loss2\n\n    y_pred = torch.sigmoid(y_pred)\n    y_pred = torch.argmax(y_pred, 1)\n    y_pred = y_pred.view(-1)\n    y_true = y_true.view(-1)\n    y_pred = y_pred.detach().cpu().numpy()\n    y_true = y_true.detach().cpu().numpy() \n\n    epoch_val_loss += y_pred.shape[0] * loss.item()\n\n    y_true_a.extend(np.eye(3)[y_true])\n    y_pred_a.extend(np.eye(3)[y_pred])\n    \n    return epoch_val_loss","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:28:44.126714Z","iopub.execute_input":"2022-07-03T20:28:44.127229Z","iopub.status.idle":"2022-07-03T20:28:44.144618Z","shell.execute_reply.started":"2022-07-03T20:28:44.127196Z","shell.execute_reply":"2022-07-03T20:28:44.143654Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"def train(net, loss_fn, optimizer, scheduler, train_loader,val_loader, metrics_log, n_epoch=10):\n    best_metrics = 0\n    device = Config.DEVICE\n    train_acc_log = []\n    val_roc_auc = []\n    train_loss = []\n    val_loss = []\n\n    for epoch in range(n_epoch):\n        print(f'Epoch {epoch + 1}')\n        net.train()\n        \n        train_size = 0\n        train_pred = 0.\n        epoch_loss = 0.0\n        epoch_val_loss = 0.0\n        \n        train_dataiter = iter(train_loader)\n        for i, batch in enumerate(tqdm(train_dataiter)):\n            epoch_loss, train_size, train_pred, loss = train_batch_step(batch, device, optimizer, loss_fn, epoch_loss, train_size, train_pred)\n            \n        scheduler.step()\n        \n        train_acc = (train_pred / train_size).detach().cpu().numpy()\n        train_loss_ = epoch_loss / len(train_dataiter)\n        \n        train_acc_log.append(train_acc)\n        train_loss.append(train_loss_)\n        \n        print('train loss: ', train_loss_)\n        print('train acc: ', train_acc)\n\n        if (epoch % Config.VAL_IN_EPOCHS) == 0:\n            with torch.no_grad():\n                net.eval()\n                \n                y_true_a = []\n                y_pred_a = []\n                \n                for batch in val_loader:\n                    epoch_val_loss = val_batch_step(batch, device, net, loss_fn, epoch_val_loss, y_true_a, y_pred_a)\n\n                roc_auc = roc_auc_score(y_true_a, y_pred_a, multi_class='ovo')\n                val_loss_v = epoch_val_loss / len(val_loader)\n                print('val loss: ', val_loss_v)\n                print(f'roc_auc: {roc_auc}')\n                \n                val_roc_auc.append(roc_auc)\n                val_loss.append(val_loss_v)\n                \n                if roc_auc > best_metrics:\n                    print('New best model with test roc auc:', roc_auc)\n                    save_model(epoch, net, optimizer, loss, roc_auc)\n                    best_metrics = roc_auc\n    \n    metrics_log['train_acc'] = list(np.squeeze(train_acc_log))\n    metrics_log['val_roc_auc'] = val_roc_auc\n    metrics_log['train_loss'] = train_loss\n    metrics_log['val_loss'] = val_loss\n    \n    return net","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:28:52.063436Z","iopub.execute_input":"2022-07-03T20:28:52.063775Z","iopub.status.idle":"2022-07-03T20:28:52.079185Z","shell.execute_reply.started":"2022-07-03T20:28:52.063747Z","shell.execute_reply":"2022-07-03T20:28:52.078293Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()\nimport gc\ngc.collect()\n\nif Config.remove_old_weights:\n    for f in glob.glob(\"./*.pt\"):\n        os.remove(f)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:28:54.650745Z","iopub.execute_input":"2022-07-03T20:28:54.651344Z","iopub.status.idle":"2022-07-03T20:28:54.957740Z","shell.execute_reply.started":"2022-07-03T20:28:54.651312Z","shell.execute_reply":"2022-07-03T20:28:54.956287Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"def get_pos_weights():\n    class_weights_ = [class_weights[0] / class_weights[1]+class_weights[2],\n    class_weights[1] / class_weights[0]+class_weights[2],\n    class_weights[2] / class_weights[0]+class_weights[1]]\n    return class_weights_\n\nclass_weights_ = get_pos_weights()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:28:56.576863Z","iopub.execute_input":"2022-07-03T20:28:56.577218Z","iopub.status.idle":"2022-07-03T20:28:56.583081Z","shell.execute_reply.started":"2022-07-03T20:28:56.577189Z","shell.execute_reply":"2022-07-03T20:28:56.581979Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"net = SWIN().to(Config.DEVICE)\n\n# from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts\n# CosineAnnealingLR(optimizer, T_max=5, )\n# CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=1)\nmetrics_log = {}\n\nif Config.train or Config.val:\n    lr = 1e-3\n    loss_fn = [torch.nn.BCEWithLogitsLoss(pos_weight=torch.FloatTensor(class_weights_).to(Config.DEVICE)), torch.nn.CrossEntropyLoss(weight=torch.FloatTensor(class_weights).to(Config.DEVICE))]\n    optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=1e-5)\n    scheduler = StepLR(optimizer, step_size=2, gamma=0.85)\n    \n    if Config.train:\n        net = train(net, loss_fn, optimizer, scheduler, train_loader, val_loader, metrics_log, n_epoch=Config.EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:31:46.971827Z","iopub.execute_input":"2022-07-03T20:31:46.972556Z","iopub.status.idle":"2022-07-03T20:31:51.314791Z","shell.execute_reply.started":"2022-07-03T20:31:46.972519Z","shell.execute_reply":"2022-07-03T20:31:51.313614Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"if Config.train:\n    sns.lineplot(data=pd.DataFrame({'train_acc': metrics_log['train_acc'], 'val_roc_auc': metrics_log['val_roc_auc']})).set_xticks(range(len(metrics_log['train_acc'])));","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:29:18.223211Z","iopub.execute_input":"2022-07-03T20:29:18.223568Z","iopub.status.idle":"2022-07-03T20:29:18.228850Z","shell.execute_reply.started":"2022-07-03T20:29:18.223538Z","shell.execute_reply":"2022-07-03T20:29:18.227866Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"if Config.train:\n    sns.lineplot(data = pd.DataFrame({'train_loss': metrics_log['train_loss'], 'val_loss': metrics_log['val_loss']})).set_xticks(range(len(metrics_log['train_acc'])));","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:29:19.483180Z","iopub.execute_input":"2022-07-03T20:29:19.483774Z","iopub.status.idle":"2022-07-03T20:29:19.489328Z","shell.execute_reply.started":"2022-07-03T20:29:19.483739Z","shell.execute_reply":"2022-07-03T20:29:19.488268Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"Fine-tuning","metadata":{}},{"cell_type":"code","source":"if Config.fine_tune:\n#     opt_params = optimizer.state_dict()\n    net.set_parameter_requires_grad(freeze=False)\n\n    lr = 5e-4\n#     optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n#     optimizer.load_state_dict(opt_params)\n    \n    optimizer.param_groups[0]['lr'] = lr\n    \n    if Config.load_weights:\n        optimizer.load_state_dict(torch.load(Config.new_current_weights_path)['optimizer_state_dict'])\n#         optimizer.load_state_dict(torch.load('./best_model_0_0.876.pt')['optimizer_state_dict'])\n        optimizer.param_groups[0]['lr'] = 5e-4\n\n    net = train(net, loss_fn, optimizer, train_loader, val_loader, n_epoch=Config.FT_EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:29:30.174159Z","iopub.execute_input":"2022-07-03T20:29:30.174736Z","iopub.status.idle":"2022-07-03T20:29:30.181061Z","shell.execute_reply.started":"2022-07-03T20:29:30.174700Z","shell.execute_reply":"2022-07-03T20:29:30.179719Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":"### Load best model weights","metadata":{}},{"cell_type":"code","source":"if Config.weights_path_var == 'old':\n    model_path = Config.weights_path\nelif Config.weights_path_var == 'new':\n    model_path = Config.new_current_weights_path\nelse:\n    print('incorrect var value')\n    \nprint(model_path)\n\nif Config.load_weights:\n    net.load_state_dict(torch.load(model_path)['model_state_dict'])","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:31:54.815655Z","iopub.execute_input":"2022-07-03T20:31:54.816410Z","iopub.status.idle":"2022-07-03T20:31:55.444439Z","shell.execute_reply.started":"2022-07-03T20:31:54.816371Z","shell.execute_reply":"2022-07-03T20:31:55.443449Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":"# Val","metadata":{}},{"cell_type":"code","source":"custom_threshold = False\n\ndef custom_threshold(preds):\n    new_preds = torch.zeros(preds.shape[0], dtype=torch.int8)\n    for i, pred in enumerate(preds):\n        if (pred[0] > 0.3) & (pred[1] < 0.6) & (pred[2] < 0.6):\n            new_preds[i] = 0\n        else:\n            new_preds[i] = torch.argmax(pred)\n        if (pred[2] > 0.3) & (pred[1] < 0.6) & (pred[0] < 0.6):\n            new_preds[i] = 2\n        else:\n            new_preds[i] = torch.argmax(pred)\n    return new_preds\n        \nwith torch.no_grad():\n    net.eval()\n    epoch_val_loss = 0.0\n    \n    y_true_a = []\n    y_pred_a = []\n    y_pred_probas = []\n    \n    for batch in val_loader:\n        x, y = batch\n        x = x.to(Config.DEVICE)\n        y = y.to(Config.DEVICE)\n        y_pred = net(x)\n        loss1 = loss_fn[0](y_pred, F.one_hot(y, num_classes=3).float())\n        loss2 = loss_fn[1](y_pred, F.one_hot(y, num_classes=3).float())\n        loss = loss1 + loss2\n        \n        y_pred = torch.sigmoid(y_pred)\n        y_pred_probas.extend(y_pred.detach().cpu().numpy())\n        \n        # todo: add custom threshold\n        if custom_threshold:\n            y_pred = custom_threshold(y_pred)\n        else:\n            y_pred = torch.argmax(y_pred, 1)\n        \n        y_true = y.detach().cpu().numpy() \n        y_pred = y_pred.view(-1).detach().cpu().numpy()\n\n        y_true_a.extend(np.eye(3)[y_true])\n        y_pred_a.extend(np.eye(3)[y_pred])\n        \n        epoch_val_loss += y_pred.shape[0] * loss.item()\n        \n    roc_auc = roc_auc_score(y_true_a, y_pred_a, multi_class='ovo')\n    print('val loss: ', epoch_val_loss / len(val_loader))\n    print(f'roc_auc: {roc_auc}')","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:32:04.568495Z","iopub.execute_input":"2022-07-03T20:32:04.568880Z","iopub.status.idle":"2022-07-03T20:32:09.122654Z","shell.execute_reply.started":"2022-07-03T20:32:04.568848Z","shell.execute_reply":"2022-07-03T20:32:09.120887Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"# mask = np.argmax(y_true_a, 1) != np.argmax(y_pred_a, 1)\n# y_true_v = np.argmax(y_true_a, 1)\n# y_pred_probas = np.squeeze(y_pred_probas)\n# y_pred_probas[mask].shape","metadata":{"execution":{"iopub.status.busy":"2022-07-03T19:33:03.444655Z","iopub.status.idle":"2022-07-03T19:33:03.445352Z","shell.execute_reply.started":"2022-07-03T19:33:03.445099Z","shell.execute_reply":"2022-07-03T19:33:03.445122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_true_v[mask][y_true_v[mask] == 1]\n# np.where(y_true_v[mask] == 2)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T19:33:03.446632Z","iopub.status.idle":"2022-07-03T19:33:03.447326Z","shell.execute_reply.started":"2022-07-03T19:33:03.447072Z","shell.execute_reply":"2022-07-03T19:33:03.447096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_pred_probas[mask]","metadata":{"execution":{"iopub.status.busy":"2022-07-03T19:33:03.448627Z","iopub.status.idle":"2022-07-03T19:33:03.449326Z","shell.execute_reply.started":"2022-07-03T19:33:03.44907Z","shell.execute_reply":"2022-07-03T19:33:03.449094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_true_a, y_pred_a))\n\nmatrix = confusion_matrix(np.argmax(y_true_a, axis=1), np.argmax(y_pred_a, axis=1))\nmatrix.diagonal()/matrix.sum(axis=0)\n\nplt.figure(figsize=(8, 6), dpi=80)\nsns.heatmap(matrix, annot=True, fmt='d')","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:32:15.697662Z","iopub.execute_input":"2022-07-03T20:32:15.698555Z","iopub.status.idle":"2022-07-03T20:32:15.953494Z","shell.execute_reply.started":"2022-07-03T20:32:15.698511Z","shell.execute_reply":"2022-07-03T20:32:15.952464Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"print(matrix)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:32:22.487743Z","iopub.execute_input":"2022-07-03T20:32:22.488108Z","iopub.status.idle":"2022-07-03T20:32:22.493952Z","shell.execute_reply.started":"2022-07-03T20:32:22.488079Z","shell.execute_reply":"2022-07-03T20:32:22.492731Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"preds = []\nfile_names_all = []\n\nwith torch.no_grad():\n    net.eval()\n    metrics = []\n    for batch in tqdm(test_loader):\n        images, file_names = batch\n        images = images.to(Config.DEVICE)\n        file_names_all.extend(file_names)\n        \n        y_pred = net(images)\n        y_pred = torch.sigmoid(y_pred)\n        y_pred = torch.argmax(y_pred, 1)\n        y_pred = y_pred.detach().cpu().numpy().tolist()\n        preds.extend(y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:32:24.878607Z","iopub.execute_input":"2022-07-03T20:32:24.878980Z","iopub.status.idle":"2022-07-03T20:32:34.102662Z","shell.execute_reply.started":"2022-07-03T20:32:24.878947Z","shell.execute_reply":"2022-07-03T20:32:34.101186Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"markdown","source":"## Submit","metadata":{}},{"cell_type":"code","source":"if Config.submit:\n    \n    submit_csv_file_name = 'swin_base_multilabel_val_spl.csv'\n\n    submit = pd.DataFrame({'ID_img': [filen.split('.')[0] for filen in file_names_all], 'class': preds})\n    submit.to_csv(submit_csv_file_name, index=False)\n    print(submit.head(5))","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:33:18.652142Z","iopub.execute_input":"2022-07-03T20:33:18.652496Z","iopub.status.idle":"2022-07-03T20:33:18.662667Z","shell.execute_reply.started":"2022-07-03T20:33:18.652466Z","shell.execute_reply":"2022-07-03T20:33:18.661734Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"display(IPython.display.Audio(url=\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\", autoplay=True))","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:32:39.748042Z","iopub.execute_input":"2022-07-03T20:32:39.748392Z","iopub.status.idle":"2022-07-03T20:32:39.757279Z","shell.execute_reply.started":"2022-07-03T20:32:39.748364Z","shell.execute_reply":"2022-07-03T20:32:39.756074Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"# from https://www.kaggle.com/getting-started/168312\nFileLink(f'./{submit_csv_file_name}')","metadata":{"execution":{"iopub.status.busy":"2022-07-03T20:36:54.170683Z","iopub.execute_input":"2022-07-03T20:36:54.171315Z","iopub.status.idle":"2022-07-03T20:36:54.177632Z","shell.execute_reply.started":"2022-07-03T20:36:54.171275Z","shell.execute_reply":"2022-07-03T20:36:54.176639Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"markdown","source":"<!-- <a href=\"\"> Download submit file </a> (past file name here) -->","metadata":{}}]}